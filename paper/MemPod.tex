
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the template for submission to ISCA 2016
% The cls file is a modified from  'sig-alternate.cls'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{sig-alternate}
%\usepackage{mathptmx} % This is Times font

%\newcommand{\ignore}[1]{}
\usepackage{fancyhdr}
\usepackage[normalem]{ulem}
\usepackage[hyphens]{url}
\usepackage{hyperref}

\usepackage{tabularx}
\usepackage{ulem}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{enumitem}% http://ctan.org/pkg/enumitem
%\usepackage{program}

\usepackage[font=small]{subcaption}

%Page dimensions
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

%Saving 3 lines from page 12
\setlength{\columnsep}{0.8cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% I need these so it compiles on my Ubuntu machine
% There's some issue with the algorithm2e package
%\makeatletter
%\newif\if@restonecol
%\makeatother
%\let\algorithm\relax
%\let\endalgorithm\relax
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[ruled]{algorithm2e}
%\usepackage{algorithm2e}


%\usepackage{algorithm2e}
%\usepackage{mathptmx} % This is Times font

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\newcommand{\microsubmissionnumber}{164}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fancypagestyle{firstpage}{
  \fancyhf{}
\setlength{\headheight}{50pt}
\renewcommand{\headrulewidth}{0pt}
  \fancyhead[C]{\normalsize{HPCA 2017 Submission
      \textbf{\#\microsubmissionnumber} -- Confidential Draft -- Do NOT Distribute!!}} 
  \pagenumbering{arabic}
}  

%%commands
\input{macros}
\newcommand{\TODO}[1]{\textcolor{red}{\todo{#1}}}
\renewcommand{\arraystretch}{1.5}

\input{remark}
%\remarktrue
\remarkfalse

%switch the % above to stop printing remarks.

% Prodromou: Switch alternative results onor off
\newif\ifOldResults
%\OldResultstrue
\OldResultsfalse

\setlist[itemize]{wide=\parindent}



%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\title {MemPod: A Clustered Architecture for Efficient and Scalable Migration in Flat Address Space Multi-level Memories}
\author{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\thispagestyle{firstpage}
\pagestyle{plain}

\begin{abstract}

%In the near future die-stacked DRAM will be present alongside off-chip memories in hybrid memory systems. A large body of recent research has explored possible uses and performance-improving mechanisms regarding such a memory configuration. The first approach is to use this new memory as a last level cache and it has been shown to be beneficial for system performance. Another approach is to use the on-chip memory as an extension of the off-chip one in a ``flat address space'' configuration, exposing more memory capacity to applications leading to performance improvement under capacity constrained workloads.
%
%Research has addressed optimization of flat-address-space memories by optimally placing ``hot page'' in the faster memory. Software managed schemes have high overheads and are coarse grained and hence slow to adapt to changes in application phases. Recently proposed hardware managed schemes operate at finer granularity than software by either using simple cache like demand driven placement or using a centralized fixed mapping scheme. The former does not consider hotness of data, whereas the latter will not scale to large memories due to its centralized approach.

In the near future, die-stacked DRAM will be increasingly
present in conjunction with 
off-chip memories in hybrid memory systems. Research on this subject revolves around using the stacked memory as a cache or as part of a flat address space. In this paper we propose MemPod, a scalable and efficient memory management mechanism for flat address space hybrid memories. MemPod monitors memory activity and periodically migrates the most frequently accessed memory pages to the faster on-chip memory. We propose a partitioned architectural organization allowing MemPod to scale efficiently with memory system capabilities. Further, we adapt algorithms from big data analytics to develop an efficient, low-cost activity tracking technique. 

Our results with multi-programmed workloads show that MemPod improves average main memory access time by up to 29\% (11\% on average) compared to the state of the art, and that will increase as the differential between memory speeds
widens.
MemPod's novel activity tracking approach leads to significant cost reduction ($\sim$6000x lower storage space requirements) and improved future prediction accuracy over prior work which maintains a separate counter per page.

\end{abstract}

\noindent \textbf{Keywords:} Memory architecture, Die-stacked memory

\input{sections/Introduction.tex}
\input{sections/Background.tex}
%\input{sections/RelatedWork.tex}
\input{sections/MEA.tex}
\input{sections/BuildingBlocks.tex}
%\input{sections/Architecture.tex}
\input{sections/ArchitectureNew.tex}
\ifOldResults
\input{sections/Results.tex}
\else
\input{sections/AltResults.tex}
\fi
\input{sections/Conclusions.tex}

%\bstctlcite{bstctl:etal, bstctl:nodash, bstctl:simpurl}
%\bibliographystyle{IEEEtranS}
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
